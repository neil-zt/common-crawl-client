{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用 Common Crawl 的網頁資料\n",
    "\n",
    "> 請依照下列的指示先完成環境建置後再執行程式。\n",
    "\n",
    "## 環境建置\n",
    "### 安裝 Dependencies\n",
    "```zsh\n",
    "pip install pandas\n",
    "pip install comcrawl \n",
    "pip install beautifulsoup4\n",
    "```\n",
    "### 更新 `comcrawl` 中的程式\n",
    "Common Crawl 組織在過去幾年內更新了他們的檔案下載連結，但 `comcrawl` 似乎因沒有被更新而無法下載 Common Crawl 的資料。請前往 `comcrawl` 函式庫所謂在的資料夾（如果使用的是 VS Code，可按住 `ctrl` 或 `command`，將滑鼠移動到 `from comcrawl import IndexClient` 中的 `comcrawl` 上並點擊）。接著請開啟 `utils/download.py`，並將下列的程式更新到對應的函式/變數名稱上：\n",
    "- `download_multiple_results`\n",
    "  ```python\n",
    "  def download_multiple_results(results: ResultList, threads: int = None) -> ResultList:\n",
    "    # multi-threaded download\n",
    "    if threads:\n",
    "        multithreaded_download = make_multithreaded(download_single_result, threads)\n",
    "        results_with_html = multithreaded_download(results)\n",
    "    # single-threaded download\n",
    "    else:\n",
    "        for result in results:\n",
    "            success = False\n",
    "            while not success:\n",
    "                try:\n",
    "                    result_with_html = download_single_result(result)\n",
    "                    results_with_html.append(result_with_html)\n",
    "                    success = True\n",
    "                except Exception as e:\n",
    "                    print(\"Library Error: download_single_result failed, retrying...\")\n",
    "    return results_with_html\n",
    "  ```\n",
    "- `URL_TEMPLATE`\n",
    "  ```python\n",
    "  https://data.commoncrawl.org/{filename}\n",
    "  ``` \n",
    "\n",
    "## 使用方法"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 指定資料的位置與時間\n",
    "在下列設定 `time_code` 和 `searching_uri`。`time_code` 可從 Common Crawl 的[官網列表](https://commoncrawl.org/the-data/get-started/)獲得。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_code = \"2022-05\"\n",
    "searching_uri = \"www.cna.com.tw/news/afe/*\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 載入需要的函式庫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from comcrawl import IndexClient\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建立下載後存放資料的資料夾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "searching_uri_dir = searching_uri.replace(\"/\", \"-\").replace(\"*\", \"-all\")\n",
    "if not os.path.exists(\"output\"):\n",
    "    os.makedirs(\"output\")\n",
    "if not os.path.exists(f\"output/{time_code}\"):\n",
    "    os.makedirs(f\"output/{time_code}\")\n",
    "if not os.path.exists(f\"output/{time_code}/{searching_uri_dir}\"):\n",
    "    os.makedirs(f\"output/{time_code}/{searching_uri_dir}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 獲取目標在 Common Crawl 資料庫中的 Index\n",
    "需要注意的是，Common Crawl Index Server 時常有著龐大的負載，因此多數時候會發生 `504 timeout` 的問題。此處的解決方法是不斷嘗試呼叫其伺服器直到收到回覆為止。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = IndexClient([time_code], verbose=True)\n",
    "success = False\n",
    "while not success:\n",
    "    try:\n",
    "        client.search(searching_uri)\n",
    "        client.results = (pd.DataFrame(client.results)\n",
    "                        .sort_values(by=\"timestamp\")\n",
    "                        .drop_duplicates(\"urlkey\", keep=\"last\")\n",
    "                        .to_dict(\"records\"))\n",
    "        pd.DataFrame(client.results).to_csv(f\"output/{time_code}/{searching_uri_dir}/index.csv\", index=False)\n",
    "        success = True\n",
    "    except:\n",
    "        print(\"Index Server Response Timeout. Retrying...\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 下載目標檔案\n",
    "這個步驟可能會要下載數千至數十萬個網頁資料，除了需要預先確認記憶體大小能夠負荷外，另請注意其可能花費數個小時。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success = False\n",
    "while not success:\n",
    "    try:\n",
    "        client.download()\n",
    "        success = True\n",
    "    except:\n",
    "        print(\"Download Server Error. Retrying...\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 將網頁中的文章解析出來\n",
    "下列提供的為很通略的文章擷取方法。如果要爬特定的網頁，可能需要特別設計擷取的步驟。前往 `/web_parse.py` 以編輯之。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from web_parse import extract_main_paragraphs\n",
    "for result in client.results:\n",
    "    extracted_text = extract_main_paragraphs(result[\"html\"])\n",
    "    if len(extracted_text) < 100:\n",
    "        continue\n",
    "    with open(f\"output/{time_code}/{searching_uri_dir}/{result['urlkey'].replace('/', '-')}.txt\", \"w\") as f:\n",
    "        f.write(extracted_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
